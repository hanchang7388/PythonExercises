# PythonExercises
根目录的下的爬虫的想法是从东大教务处查课表的地方爬取学生信息。但是遇到的问题是每次爬取9个左右就404了。
构造了cookies和header来模拟浏览器行为，也设置随机时间间隔访问防止反爬虫策略，无法访问的页面自动尝试重新访问，但情况依然没有改善。
没想到学校的安全策略这么好，感觉爬虫和反爬虫之间的博弈主要在于成本问题，假如爬虫者使用多线程+代理IP（或者ADSL网络）的策略，抑或用selenium等工具，那么大部分网站都无法抵抗，但是金钱、时间成本太高没必要继续做。反爬虫也是，用算法识别网络访问的行为，封禁IP等，也会造成开发的难度和用户体验的损失。爬虫与反爬虫还真是有很多可以讲。
暂时不继续搞这个了，等有时间，可以用多线程试试。
